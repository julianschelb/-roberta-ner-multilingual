{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Finetuning BLOOM for NER: Evaluate Model\n"," "]},{"cell_type":"markdown","metadata":{},"source":["***"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-09-04T17:17:23.428297Z","iopub.status.busy":"2022-09-04T17:17:23.427338Z","iopub.status.idle":"2022-09-04T17:17:31.843100Z","shell.execute_reply":"2022-09-04T17:17:31.842031Z","shell.execute_reply.started":"2022-09-04T17:17:23.427831Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/julian/Documents/Workspace_Python/bloom-ner-multilingual/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import (BloomTokenizerFast,\n","                          BloomForTokenClassification,\n","                          DataCollatorForTokenClassification, \n","                          AutoModelForTokenClassification, \n","                          TrainingArguments, Trainer)\n","from datasets import load_dataset, load_metric, concatenate_datasets, DatasetDict\n","from pprint import pprint\n","import numpy as np\n","import pickle\n","import torch\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["## Load Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["data_path = \"./data/dataset_processed.pkl\"\n","with open(data_path, 'rb') as pickle_file:\n","    dataset = pickle.load(file=pickle_file)"]},{"cell_type":"markdown","metadata":{},"source":["## Load Model and Tokenizer"]},{"cell_type":"markdown","metadata":{},"source":["The list of available Models can be found here: https://huggingface.co/docs/transformers/model_doc/bloom\n","\n","Load Model which can be finetuned:"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-09-04T17:20:35.622912Z","iopub.status.busy":"2022-09-04T17:20:35.622133Z","iopub.status.idle":"2022-09-04T17:20:35.820853Z","shell.execute_reply":"2022-09-04T17:20:35.819482Z","shell.execute_reply.started":"2022-09-04T17:20:35.622874Z"},"trusted":true},"outputs":[],"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-04T17:20:35.823680Z","iopub.status.busy":"2022-09-04T17:20:35.823343Z","iopub.status.idle":"2022-09-04T17:20:35.836229Z","shell.execute_reply":"2022-09-04T17:20:35.832509Z","shell.execute_reply.started":"2022-09-04T17:20:35.823652Z"},"trusted":true},"outputs":[],"source":["label_list = dataset[\"train\"].features[f\"ner_tags\"].feature.names"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-09-04T17:17:33.656105Z","iopub.status.busy":"2022-09-04T17:17:33.655459Z","iopub.status.idle":"2022-09-04T17:19:25.869219Z","shell.execute_reply":"2022-09-04T17:19:25.868230Z","shell.execute_reply.started":"2022-09-04T17:17:33.656069Z"},"trusted":true},"outputs":[],"source":["model_name = \"bloom-560m\"\n","tokenizer = BloomTokenizerFast.from_pretrained(f\"bigscience/{model_name}\", add_prefix_space=True)\n","model = AutoModelForTokenClassification.from_pretrained(f\"bigscience/{model_name}\", num_labels=len(label_list))#.cuda()"]},{"cell_type":"markdown","metadata":{},"source":["**Define Metrics:**\n","\n","See https://huggingface.co/course/chapter7/2#metrics"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-09-04T17:23:52.528408Z","iopub.status.busy":"2022-09-04T17:23:52.527563Z","iopub.status.idle":"2022-09-04T17:23:53.180502Z","shell.execute_reply":"2022-09-04T17:23:53.179321Z","shell.execute_reply.started":"2022-09-04T17:23:52.528364Z"},"trusted":true},"outputs":[],"source":["metric = load_metric(\"seqeval\")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-09-04T17:23:54.086675Z","iopub.status.busy":"2022-09-04T17:23:54.086175Z","iopub.status.idle":"2022-09-04T17:23:54.108136Z","shell.execute_reply":"2022-09-04T17:23:54.107103Z","shell.execute_reply.started":"2022-09-04T17:23:54.086641Z"},"trusted":true},"outputs":[],"source":["example = dataset[\"train\"][150]\n","labels = [label_list[i] for i in example[f\"ner_tags\"]]\n","metric.compute(predictions=[labels], references=[labels])"]},{"cell_type":"markdown","metadata":{},"source":["**Calculate Accuracy:**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["predictions, labels, _ = trainer.predict(dataset[\"test\"])\n","predictions = np.argmax(predictions, axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["true_labels = [\n","    [label_names[l] for l in label  if l != -100] \n","    for label in labels\n","]\n","\n","true_predictions = [\n","    [label_names[p] for (p, l) in zip(prediction, label)  if l != -100]\n","    for prediction, label in zip(predictions, labels)\n","]\n","\n","results = metric.compute(predictions=true_predictions, references=true_labels)\n","pprint(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["training_history = trainer.state.log_history\n","\n","# Training\n","epochs = [epoch.get(\"epoch\") for epoch in  training_history if epoch.get(\"loss\") is not None]\n","steps = [epoch.get(\"step\") for epoch in  training_history if epoch.get(\"loss\") is not None]\n","loss = [epoch.get(\"loss\") for epoch in  training_history if epoch.get(\"loss\") is not None]\n","\n","# Eval\n","eval_epochs = [epoch.get(\"epoch\") for epoch in  training_history if epoch.get(\"eval_loss\") is not None]\n","eval_steps = [epoch.get(\"step\") for epoch in  training_history if epoch.get(\"eval_loss\") is not None]\n","eval_loss = [epoch.get(\"eval_loss\") for epoch in  training_history if epoch.get(\"eval_loss\") is not None]\n","eval_precision = [epoch.get(\"eval_precision\") for epoch in  training_history if epoch.get(\"eval_precision\") is not None]\n","eval_recall = [epoch.get(\"eval_recall\") for epoch in  training_history if epoch.get(\"eval_recall\") is not None]\n","eval_f1 = [epoch.get(\"eval_recall\") for epoch in  training_history if epoch.get(\"eval_f1\") is not None]\n","eval_accuracy = [epoch.get(\"eval_accuracy\") for epoch in  training_history if epoch.get(\"eval_accuracy\") is not None]\n","\n","eval_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["p = sns.lineplot( x=steps, y=loss)\n","p.set_xlabel(\"Training Steps\")\n","p.set_ylabel(\"Loss\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["p = sns.lineplot(x=eval_steps, y=eval_loss)\n","p.set_xlabel(\"Eval Steps\")\n","p.set_ylabel(\"Loss\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["p = sns.lineplot(x=eval_steps, y=eval_accuracy)\n","p.set_xlabel(\"Eval Steps\")\n","p.set_ylabel(\"Loss\")"]},{"cell_type":"markdown","metadata":{},"source":["## Use Fine-tuned Model:"]},{"cell_type":"markdown","metadata":{},"source":["Load checkpoint:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_tuned = BloomForTokenClassification.from_pretrained(\"./results/checkpoint-final/\")"]},{"cell_type":"markdown","metadata":{},"source":["Set correct class labels:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["label_names = dataset[\"train\"].features[f\"ner_tags\"].feature.names\n","\n","id2label = {id : label for id, label in enumerate(label_names)}\n","label2id = {label: id for id, label in enumerate(label_names)}\n","\n","model_tuned.config.id2label = id2label\n","model_tuned.config.label2id = label2id"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_tuned.config.id2label"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["text = \"Für Richard Phillips Feynman war es immer wichtig in New York, die unanschaulichen Gesetzmäßigkeiten der Quantenphysik Laien und Studenten nahezubringen und verständlich zu machen.\"\n","\n","inputs = tokenizer(\n","    text, \n","    add_special_tokens=False, return_tensors=\"pt\"\n",")\n","\n","with torch.no_grad():\n","    logits = model_tuned(**inputs).logits\n","\n","predicted_token_class_ids = logits.argmax(-1)\n","\n","# Note that tokens are classified rather then input words which means that\n","# there might be more predicted token classes than words.\n","# Multiple token classes might account for the same word\n","predicted_tokens_classes = [model_tuned.config.id2label[t.item()] for t in predicted_token_class_ids[0]]\n","predicted_tokens_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["text = \"In December 1903 in France the Royal Swedish Academy of Sciences awarded Pierre Curie, Marie Curie, and Henri Becquerel the Nobel Prize in Physics\"\n","\n","inputs = tokenizer(\n","    text, \n","    add_special_tokens=False, return_tensors=\"pt\"\n",")\n","\n","with torch.no_grad():\n","    logits = model_tuned(**inputs).logits\n","\n","predicted_token_class_ids = logits.argmax(-1)\n","\n","# Note that tokens are classified rather then input words which means that\n","# there might be more predicted token classes than words.\n","# Multiple token classes might account for the same word\n","predicted_tokens_classes = [model_tuned.config.id2label[t.item()] for t in predicted_token_class_ids[0]]\n","predicted_tokens_classes"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"72a3b8d639f2747ab586194b4ca9ce337f16fb375d739e56b4629a0a8f86dcaa"}}},"nbformat":4,"nbformat_minor":4}
