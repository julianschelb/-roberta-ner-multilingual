{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning RoBERTa for NER: Train Model\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:17:23.428297Z",
     "iopub.status.busy": "2022-09-04T17:17:23.427338Z",
     "iopub.status.idle": "2022-09-04T17:17:31.843100Z",
     "shell.execute_reply": "2022-09-04T17:17:31.842031Z",
     "shell.execute_reply.started": "2022-09-04T17:17:23.427831Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import (BertTokenizerFast,\n",
    "                          RobertaTokenizerFast,\n",
    "                          AutoTokenizer,\n",
    "                          BertForTokenClassification,\n",
    "                          RobertaForTokenClassification,\n",
    "                          DataCollatorForTokenClassification, \n",
    "                          AutoModelForTokenClassification, \n",
    "                          TrainingArguments, Trainer)\n",
    "from datasets import load_dataset, load_metric, concatenate_datasets, DatasetDict\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dill as pickle\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/dataset_processed.pkl\"\n",
    "with open(data_path, 'rb') as pickle_file:\n",
    "    dataset = pickle.load(file=pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [\"''\", 'Super', 'World', 'of', 'Sports', \"''\", \"'\"],\n",
       " 'ner_tags': [0, 3, 4, 4, 4, 0, 0],\n",
       " 'langs': ['en', 'en', 'en', 'en', 'en', 'en', 'en'],\n",
       " 'spans': ['ORG: Super World of Sports'],\n",
       " 'input_ids': [5106, 4265, 6661, 111, 39170, 5106, 242],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [0, 3, 4, 4, 4, 0, 0]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about model variants can be found here: https://huggingface.co/docs/transformers/model_doc/roberta\n",
    "\n",
    "Load Model which can be finetuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:20:35.622912Z",
     "iopub.status.busy": "2022-09-04T17:20:35.622133Z",
     "iopub.status.idle": "2022-09-04T17:20:35.820853Z",
     "shell.execute_reply": "2022-09-04T17:20:35.819482Z",
     "shell.execute_reply.started": "2022-09-04T17:20:35.622874Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:20:35.823680Z",
     "iopub.status.busy": "2022-09-04T17:20:35.823343Z",
     "iopub.status.idle": "2022-09-04T17:20:35.836229Z",
     "shell.execute_reply": "2022-09-04T17:20:35.832509Z",
     "shell.execute_reply.started": "2022-09-04T17:20:35.823652Z"
    }
   },
   "outputs": [],
   "source": [
    "label_list = dataset[\"train\"].features[f\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:17:33.656105Z",
     "iopub.status.busy": "2022-09-04T17:17:33.655459Z",
     "iopub.status.idle": "2022-09-04T17:19:25.869219Z",
     "shell.execute_reply": "2022-09-04T17:19:25.868230Z",
     "shell.execute_reply.started": "2022-09-04T17:17:33.656069Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at /home/pop529700/.cache/huggingface/hub/models--xlm-roberta-large/snapshots/b2a6150f8be56457baf80c74342cc424080260f0/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading file sentencepiece.bpe.model from cache at /home/pop529700/.cache/huggingface/hub/models--xlm-roberta-large/snapshots/b2a6150f8be56457baf80c74342cc424080260f0/sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at /home/pop529700/.cache/huggingface/hub/models--xlm-roberta-large/snapshots/b2a6150f8be56457baf80c74342cc424080260f0/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /home/pop529700/.cache/huggingface/hub/models--xlm-roberta-large/snapshots/b2a6150f8be56457baf80c74342cc424080260f0/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/pop529700/.cache/huggingface/hub/models--xlm-roberta-large/snapshots/b2a6150f8be56457baf80c74342cc424080260f0/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/pop529700/.cache/huggingface/hub/models--xlm-roberta-large/snapshots/b2a6150f8be56457baf80c74342cc424080260f0/pytorch_model.bin\n",
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"xlm-roberta-large\" #\"bert-base-multilingual-cased\" #xlm-roberta-large\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"{model_name}\", add_prefix_space=True) #AutoTokenizer(use_fast = True)\n",
    "model = AutoModelForTokenClassification.from_pretrained(f\"{model_name}\", num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:20:35.615127Z",
     "iopub.status.busy": "2022-09-04T17:20:35.614018Z",
     "iopub.status.idle": "2022-09-04T17:20:35.620697Z",
     "shell.execute_reply": "2022-09-04T17:20:35.619590Z",
     "shell.execute_reply.started": "2022-09-04T17:20:35.615098Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the Model:\n",
    "\n",
    "see https://github.com/huggingface/transformers/blob/v4.21.1/src/transformers/modeling_utils.py#L829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:20:49.161724Z",
     "iopub.status.busy": "2022-09-04T17:20:49.161376Z",
     "iopub.status.idle": "2022-09-04T17:20:49.174161Z",
     "shell.execute_reply": "2022-09-04T17:20:49.173299Z",
     "shell.execute_reply.started": "2022-09-04T17:20:49.161688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 558848007\n",
      "Expected Input Dict: input_ids\n",
      "FLOPS needed per Training Sample: 23471616294\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters:\", model.num_parameters())\n",
    "print(\"Expected Input Dict:\", model.main_input_name )\n",
    "\n",
    "# Estimate FLOPS needed for one training example\n",
    "sample = dataset[\"train\"][0]\n",
    "sample[\"input_ids\"] = torch.Tensor(sample[\"input_ids\"])\n",
    "flops_est = model.floating_point_ops(input_dict = sample, exclude_embeddings = False)\n",
    "\n",
    "print(\"FLOPS needed per Training Sample:\", flops_est )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'spans', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'spans', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'spans', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Optimizer:**\n",
    "\n",
    "See https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#transformers.Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:20:49.176350Z",
     "iopub.status.busy": "2022-09-04T17:20:49.175774Z",
     "iopub.status.idle": "2022-09-04T17:20:49.181946Z",
     "shell.execute_reply": "2022-09-04T17:20:49.180928Z",
     "shell.execute_reply.started": "2022-09-04T17:20:49.176314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 312.5\n"
     ]
    }
   ],
   "source": [
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "# A training step is one gradient update. In one step batch_size examples are processed.\n",
    "# An epoch consists of one full cycle through the training data. \n",
    "# This is usually many steps. As an example, if you have 2,000 images and use\n",
    "# a batch size of 10 an epoch consists of:\n",
    "num_steps = (len(dataset[\"train\"]) / batch_size) * num_epochs\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-6, weight_decay=0.01, no_deprecation_warning= True)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps= num_steps \n",
    ")\n",
    "\n",
    "print(\"Steps:\", num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Metrics:**\n",
    "\n",
    "See https://huggingface.co/course/chapter7/2#metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:23:52.528408Z",
     "iopub.status.busy": "2022-09-04T17:23:52.527563Z",
     "iopub.status.idle": "2022-09-04T17:23:53.180502Z",
     "shell.execute_reply": "2022-09-04T17:23:53.179321Z",
     "shell.execute_reply.started": "2022-09-04T17:23:52.528364Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:23:54.086675Z",
     "iopub.status.busy": "2022-09-04T17:23:54.086175Z",
     "iopub.status.idle": "2022-09-04T17:23:54.108136Z",
     "shell.execute_reply": "2022-09-04T17:23:54.107103Z",
     "shell.execute_reply.started": "2022-09-04T17:23:54.086641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 3},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[\"train\"][150]\n",
    "labels = [label_list[i] for i in example[f\"labels\"]]\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set correct class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:23:54.949476Z",
     "iopub.status.busy": "2022-09-04T17:23:54.949090Z",
     "iopub.status.idle": "2022-09-04T17:23:54.956761Z",
     "shell.execute_reply": "2022-09-04T17:23:54.955061Z",
     "shell.execute_reply.started": "2022-09-04T17:23:54.949441Z"
    }
   },
   "outputs": [],
   "source": [
    "label_names = dataset[\"train\"].features[f\"ner_tags\"].feature.names\n",
    "\n",
    "id2label = {id : label for id, label in enumerate(label_names)}\n",
    "label2id = {label: id for id, label in enumerate(label_names)}\n",
    "\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:23:55.633459Z",
     "iopub.status.busy": "2022-09-04T17:23:55.633071Z",
     "iopub.status.idle": "2022-09-04T17:23:55.639657Z",
     "shell.execute_reply": "2022-09-04T17:23:55.638357Z",
     "shell.execute_reply.started": "2022-09-04T17:23:55.633426Z"
    }
   },
   "source": [
    "Define callback function to evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:23:55.991541Z",
     "iopub.status.busy": "2022-09-04T17:23:55.990958Z",
     "iopub.status.idle": "2022-09-04T17:23:56.000348Z",
     "shell.execute_reply": "2022-09-04T17:23:55.998152Z",
     "shell.execute_reply.started": "2022-09-04T17:23:55.991502Z"
    }
   },
   "outputs": [],
   "source": [
    "label_names = model.config.id2label\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    true_labels = [[label_names[l] for l in label  if l != -100] for label in labels]\n",
    "    #true_predictions = [model.config.id2label[t.item()] for t in predictions]\n",
    "    \n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label)  if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove unnecessary columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\"tokens\", \"ner_tags\", \"langs\", \"spans\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set further Training Arguments:**\n",
    "\n",
    "See https://huggingface.co/docs/transformers/v4.21.2/en/main_classes/trainer#transformers.TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:23:56.904243Z",
     "iopub.status.busy": "2022-09-04T17:23:56.903622Z",
     "iopub.status.idle": "2022-09-04T17:23:56.925735Z",
     "shell.execute_reply": "2022-09-04T17:23:56.924817Z",
     "shell.execute_reply.started": "2022-09-04T17:23:56.904204Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    save_strategy= \"no\",# \"epoch\",\n",
    "    #save_steps = 100000,\n",
    "    remove_unused_columns = True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps = 20,\n",
    "    #load_best_model_at_end=True,\n",
    "    logging_strategy = \"steps\",\n",
    "    logging_steps = 20,\n",
    "    #learning_rate= 2e-5,\n",
    "    #auto_find_batch_size = True,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    #gradient_accumulation_steps=4,\n",
    "    #optim=\"adamw_torch\",\n",
    "    num_train_epochs=num_epochs,\n",
    "    #weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "GPU used by Kaggle: https://www.nvidia.com/de-de/data-center/tesla-p100/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:23:58.843624Z",
     "iopub.status.busy": "2022-09-04T17:23:58.842692Z",
     "iopub.status.idle": "2022-09-04T17:23:59.968744Z",
     "shell.execute_reply": "2022-09-04T17:23:59.967514Z",
     "shell.execute_reply.started": "2022-09-04T17:23:58.843577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan  7 12:07:22 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A40          Off  | 00000000:01:00.0 Off |                    0 |\n",
      "|  0%   47C    P0    80W / 300W |  12091MiB / 46068MiB |     45%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A40          Off  | 00000000:43:00.0 Off |                    0 |\n",
      "|  0%   49C    P0    82W / 300W |   1223MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   1549808      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    0   N/A  N/A   1860009      C   ...s/transformers/bin/python    12065MiB |\n",
      "|    1   N/A  N/A   1549808      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    1   N/A  N/A   1860009      C   ...s/transformers/bin/python     1197MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T17:23:59.972792Z",
     "iopub.status.busy": "2022-09-04T17:23:59.971064Z",
     "iopub.status.idle": "2022-09-04T17:40:47.605893Z",
     "shell.execute_reply": "2022-09-04T17:40:47.604419Z",
     "shell.execute_reply.started": "2022-09-04T17:23:59.972745Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 160\n",
      "  Number of trainable parameters = 558848007\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/pop529700/.pyenv/versions/3.10.8/envs/transformers/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 01:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.792100</td>\n",
       "      <td>1.529250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.526300</td>\n",
       "      <td>1.306749</td>\n",
       "      <td>0.068003</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>0.043734</td>\n",
       "      <td>0.508527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.285600</td>\n",
       "      <td>1.086003</td>\n",
       "      <td>0.162504</td>\n",
       "      <td>0.190909</td>\n",
       "      <td>0.175565</td>\n",
       "      <td>0.634634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.071300</td>\n",
       "      <td>0.873305</td>\n",
       "      <td>0.290445</td>\n",
       "      <td>0.347934</td>\n",
       "      <td>0.316601</td>\n",
       "      <td>0.709249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.879700</td>\n",
       "      <td>0.782177</td>\n",
       "      <td>0.398120</td>\n",
       "      <td>0.437603</td>\n",
       "      <td>0.416929</td>\n",
       "      <td>0.759101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>0.663680</td>\n",
       "      <td>0.461480</td>\n",
       "      <td>0.504959</td>\n",
       "      <td>0.482242</td>\n",
       "      <td>0.790751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.613700</td>\n",
       "      <td>0.647533</td>\n",
       "      <td>0.486697</td>\n",
       "      <td>0.566942</td>\n",
       "      <td>0.523764</td>\n",
       "      <td>0.798786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.573400</td>\n",
       "      <td>0.580293</td>\n",
       "      <td>0.526376</td>\n",
       "      <td>0.573140</td>\n",
       "      <td>0.548764</td>\n",
       "      <td>0.820679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "/home/pop529700/.pyenv/versions/3.10.8/envs/transformers/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=160, training_loss=1.059322726726532, metrics={'train_runtime': 98.4306, 'train_samples_per_second': 50.797, 'train_steps_per_second': 1.626, 'total_flos': 387727231040688.0, 'train_loss': 1.059322726726532, 'epoch': 5.0})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.5802927017211914\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Eval Loss: {eval_results['eval_loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving the fine tuned model & tokenizer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-final/\n",
      "Configuration saved in ./results/checkpoint-final/config.json\n",
      "Model weights saved in ./results/checkpoint-final/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-final/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-final/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(f'./results/checkpoint-final/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Training History:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'torch._C.Generator' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m data_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./results/checkpoint-final/trainer.pkl\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(data_path, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m pickle_file:\n\u001b[0;32m----> 3\u001b[0m     pickle\u001b[39m.\u001b[39;49mdump(obj \u001b[39m=\u001b[39;49m trainer, file\u001b[39m=\u001b[39;49mpickle_file)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/transformers/lib/python3.10/site-packages/dill/_dill.py:235\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol, byref, fmode, recurse, **kwds)\u001b[0m\n\u001b[1;32m    233\u001b[0m _kwds \u001b[39m=\u001b[39m kwds\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    234\u001b[0m _kwds\u001b[39m.\u001b[39mupdate(\u001b[39mdict\u001b[39m(byref\u001b[39m=\u001b[39mbyref, fmode\u001b[39m=\u001b[39mfmode, recurse\u001b[39m=\u001b[39mrecurse))\n\u001b[0;32m--> 235\u001b[0m Pickler(file, protocol, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_kwds)\u001b[39m.\u001b[39;49mdump(obj)\n\u001b[1;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/transformers/lib/python3.10/site-packages/dill/_dill.py:394\u001b[0m, in \u001b[0;36mPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(\u001b[39mself\u001b[39m, obj): \u001b[39m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     logger\u001b[39m.\u001b[39mtrace_setup(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 394\u001b[0m     StockPickler\u001b[39m.\u001b[39;49mdump(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mstart_framing()\n\u001b[0;32m--> 487\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave(obj)\n\u001b[1;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(STOP)\n\u001b[1;32m    489\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mend_framing()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/transformers/lib/python3.10/site-packages/dill/_dill.py:388\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    386\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    387\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 388\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         save(state)\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/transformers/lib/python3.10/site-packages/dill/_dill.py:388\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    386\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    387\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 388\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/transformers/lib/python3.10/site-packages/dill/_dill.py:1186\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1186\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1187\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1188\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:972\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    971\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 972\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:998\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    997\u001b[0m         save(k)\n\u001b[0;32m--> 998\u001b[0m         save(v)\n\u001b[1;32m    999\u001b[0m     write(SETITEMS)\n\u001b[1;32m   1000\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[0;31m[... skipping similar frames: Pickler.save at line 388 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         save(state)\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Pickler.save at line 388 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/transformers/lib/python3.10/site-packages/dill/_dill.py:1186\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1186\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1187\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1188\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:972\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    971\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 972\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:998\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    997\u001b[0m         save(k)\n\u001b[0;32m--> 998\u001b[0m         save(v)\n\u001b[1;32m    999\u001b[0m     write(SETITEMS)\n\u001b[1;32m   1000\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[0;31m[... skipping similar frames: Pickler.save at line 388 (3 times), _Pickler._batch_setitems at line 998 (1 times), _Pickler.save at line 603 (1 times), _Pickler.save at line 560 (1 times), _Pickler.save_dict at line 972 (1 times), save_module_dict at line 1186 (1 times), _Pickler.save_reduce at line 717 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         save(state)\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Pickler.save at line 388 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/transformers/lib/python3.10/site-packages/dill/_dill.py:1186\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1186\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1187\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1188\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:972\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    971\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 972\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:998\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    997\u001b[0m         save(k)\n\u001b[0;32m--> 998\u001b[0m         save(v)\n\u001b[1;32m    999\u001b[0m     write(SETITEMS)\n\u001b[1;32m   1000\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/transformers/lib/python3.10/site-packages/dill/_dill.py:388\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    386\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    387\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 388\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/pickle.py:578\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    576\u001b[0m reduce \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__reduce_ex__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     rv \u001b[39m=\u001b[39m reduce(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproto)\n\u001b[1;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m     reduce \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__reduce__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'torch._C.Generator' object"
     ]
    }
   ],
   "source": [
    "data_path = \"./results/checkpoint-final/trainer.pkl\"\n",
    "with open(data_path, 'wb') as pickle_file:\n",
    "    pickle.dump(obj = trainer, file=pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./results/checkpoint-final/training_args.pkl\"\n",
    "with open(data_path, 'wb') as pickle_file:\n",
    "    pickle.dump(obj = trainer.args, file=pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./results/checkpoint-final/training_history.pkl\"\n",
    "with open(data_path, 'wb') as pickle_file:\n",
    "    pickle.dump(obj = trainer.state, file=pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(dataset[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC': {'f1': 0.5492468134414833,\n",
      "         'number': 880,\n",
      "         'precision': 0.5602836879432624,\n",
      "         'recall': 0.5386363636363637},\n",
      " 'ORG': {'f1': 0.4060339409176618,\n",
      "         'number': 758,\n",
      "         'precision': 0.3877551020408163,\n",
      "         'recall': 0.4261213720316623},\n",
      " 'PER': {'f1': 0.6789413118527042,\n",
      "         'number': 782,\n",
      "         'precision': 0.6171548117154811,\n",
      "         'recall': 0.7544757033248082},\n",
      " 'overall_accuracy': 0.8206789111183995,\n",
      " 'overall_f1': 0.5487636003956479,\n",
      " 'overall_precision': 0.5263757115749526,\n",
      " 'overall_recall': 0.5731404958677686}\n"
     ]
    }
   ],
   "source": [
    "true_labels = [\n",
    "    [label_names[l] for l in label  if l != -100] \n",
    "    for label in labels\n",
    "]\n",
    "\n",
    "true_predictions = [\n",
    "    [label_names[p] for (p, l) in zip(prediction, label)  if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c97fe7fd1c286c8419eb1bea19acb7c2170e8f8ba541cc471414a0cdc49a8156"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
