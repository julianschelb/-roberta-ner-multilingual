{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning BLOOM for NER: Preprocess Corpus\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:10.031751Z",
     "iopub.status.busy": "2022-09-04T22:12:10.031387Z",
     "iopub.status.idle": "2022-09-04T22:12:11.866792Z",
     "shell.execute_reply": "2022-09-04T22:12:11.865515Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/Documents/Workspace_Python/bloom-ner-multilingual/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (BloomTokenizerFast,\n",
    "                          BloomForTokenClassification,\n",
    "                          DataCollatorForTokenClassification, \n",
    "                          AutoModelForTokenClassification, \n",
    "                          TrainingArguments, Trainer)\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "import pickle\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of available Models can be found here: https://huggingface.co/docs/transformers/model_doc/bloom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:11.871856Z",
     "iopub.status.busy": "2022-09-04T22:12:11.871520Z",
     "iopub.status.idle": "2022-09-04T22:12:15.832555Z",
     "shell.execute_reply": "2022-09-04T22:12:15.831245Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"bloom-560m\"\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(f\"bigscience/{model_name}\", add_prefix_space=True)\n",
    "#model = BloomForTokenClassification.from_pretrained(f\"bigscience/{model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:15.837803Z",
     "iopub.status.busy": "2022-09-04T22:12:15.837570Z",
     "iopub.status.idle": "2022-09-04T22:12:15.846191Z",
     "shell.execute_reply": "2022-09-04T22:12:15.844952Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"./data/dataset_multilingual.pkl\"\n",
    "with open(data_path, 'rb') as pickle_file:\n",
    "    dataset = pickle.load(file=pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize a Single Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:15.851458Z",
     "iopub.status.busy": "2022-09-04T22:12:15.851264Z",
     "iopub.status.idle": "2022-09-04T22:12:15.857695Z",
     "shell.execute_reply": "2022-09-04T22:12:15.856662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['List', 'of', 'Fly', 'wheel', ',', 'Sh', 'yster', ',', 'and', 'Fly', 'wheel', '(', '1990', 'radio', 'series', ')', 'epis', 'odes']\n"
     ]
    }
   ],
   "source": [
    "example = dataset[\"train\"][50]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample after Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:15.862455Z",
     "iopub.status.busy": "2022-09-04T22:12:15.862264Z",
     "iopub.status.idle": "2022-09-04T22:12:15.873277Z",
     "shell.execute_reply": "2022-09-04T22:12:15.872211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [4378, 3825, 141473, 212546, 15, 8027, 182848, 15, 392, 141473, 212546, 11, 50539, 57113, 79266, 12, 132129, 8694], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:15.877923Z",
     "iopub.status.busy": "2022-09-04T22:12:15.877734Z",
     "iopub.status.idle": "2022-09-04T22:12:15.883845Z",
     "shell.execute_reply": "2022-09-04T22:12:15.882930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 13]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input.word_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:15.888511Z",
     "iopub.status.busy": "2022-09-04T22:12:15.888285Z",
     "iopub.status.idle": "2022-09-04T22:12:15.893688Z",
     "shell.execute_reply": "2022-09-04T22:12:15.892683Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenizeInputs(inputs):\n",
    "    \n",
    "    tokenized_inputs = tokenizer(inputs[\"tokens\"], max_length = 2048, truncation=True, is_split_into_words=True)\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "    ner_tags = inputs[\"ner_tags\"]\n",
    "    labels = [ner_tags[word_id] for word_id in word_ids]\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    \n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:15.898275Z",
     "iopub.status.busy": "2022-09-04T22:12:15.898020Z",
     "iopub.status.idle": "2022-09-04T22:12:15.904166Z",
     "shell.execute_reply": "2022-09-04T22:12:15.903361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [4378, 3825, 152605, 265, 177941], 'attention_mask': [1, 1, 1, 1, 1], 'labels': [3, 4, 4, 4, 4]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[\"train\"][100]\n",
    "tokenizeInputs(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:15.909420Z",
     "iopub.status.busy": "2022-09-04T22:12:15.909162Z",
     "iopub.status.idle": "2022-09-04T22:12:16.548707Z",
     "shell.execute_reply": "2022-09-04T22:12:16.547387Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/julian/.cache/huggingface/datasets/wikiann/en/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e/cache-1dd4ec44a00403f4.arrow\n",
      "Loading cached processed dataset at /home/julian/.cache/huggingface/datasets/wikiann/en/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e/cache-383eff4844864629.arrow\n",
      "Loading cached processed dataset at /home/julian/.cache/huggingface/datasets/wikiann/en/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e/cache-939314c6a18cfc0a.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenizeInputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle Dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:16.553826Z",
     "iopub.status.busy": "2022-09-04T22:12:16.553614Z",
     "iopub.status.idle": "2022-09-04T22:12:16.600567Z",
     "shell.execute_reply": "2022-09-04T22:12:16.599295Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count of Tokens in the Training Set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:16.605847Z",
     "iopub.status.busy": "2022-09-04T22:12:16.605642Z",
     "iopub.status.idle": "2022-09-04T22:12:37.145913Z",
     "shell.execute_reply": "2022-09-04T22:12:37.144495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in Training Set: 1486538\n"
     ]
    }
   ],
   "source": [
    "token_count = 0\n",
    "for sample in tokenized_dataset[\"train\"]:\n",
    "    token_count = token_count + len(sample[\"labels\"])\n",
    "    \n",
    "print(\"Tokens in Training Set:\", token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove unnecessary columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:37.151411Z",
     "iopub.status.busy": "2022-09-04T22:12:37.151166Z",
     "iopub.status.idle": "2022-09-04T22:12:37.162851Z",
     "shell.execute_reply": "2022-09-04T22:12:37.162161Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns([\"tokens\", \"ner_tags\", \"langs\", \"spans\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save processed Dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:12:37.166629Z",
     "iopub.status.busy": "2022-09-04T22:12:37.166302Z",
     "iopub.status.idle": "2022-09-04T22:12:37.171926Z",
     "shell.execute_reply": "2022-09-04T22:12:37.170777Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"./data/dataset_processed.pkl\"\n",
    "with open(data_path, 'wb') as pickle_file:\n",
    "    pickle.dump(obj = dataset, file=pickle_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "72a3b8d639f2747ab586194b4ca9ce337f16fb375d739e56b4629a0a8f86dcaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
