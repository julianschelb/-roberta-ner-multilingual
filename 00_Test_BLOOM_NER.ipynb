{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Testing BLOOM for Token Classification"]},{"cell_type":"markdown","metadata":{},"source":["***"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-09-04T17:17:23.428297Z","iopub.status.busy":"2022-09-04T17:17:23.427338Z","iopub.status.idle":"2022-09-04T17:17:31.843100Z","shell.execute_reply":"2022-09-04T17:17:31.842031Z","shell.execute_reply.started":"2022-09-04T17:17:23.427831Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/julian/Documents/Workspace_Python/bloom-ner-multilingual/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import (BloomTokenizerFast,\n","                          BloomForTokenClassification,\n","                          DataCollatorForTokenClassification, \n","                          AutoModelForTokenClassification, \n","                          TrainingArguments, Trainer)\n","from datasets import load_dataset, concatenate_datasets\n","import torch\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["## Use Pretrained Model"]},{"cell_type":"markdown","metadata":{},"source":["**Load Model ans Tokenizer:**\n","\n","The list of available Models can be found here: https://huggingface.co/docs/transformers/model_doc/bloom"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-09-04T17:17:33.656105Z","iopub.status.busy":"2022-09-04T17:17:33.655459Z","iopub.status.idle":"2022-09-04T17:19:25.869219Z","shell.execute_reply":"2022-09-04T17:19:25.868230Z","shell.execute_reply.started":"2022-09-04T17:17:33.656069Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading pytorch_model.bin: 100%|██████████| 1.04G/1.04G [06:17<00:00, 2.96MB/s]\n","Some weights of BloomForTokenClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model_name = \"bloom-560m\"\n","tokenizer = BloomTokenizerFast.from_pretrained(f\"bigscience/{model_name}\", add_prefix_space=True)\n","model = BloomForTokenClassification.from_pretrained(f\"bigscience/{model_name}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-04T17:19:25.871663Z","iopub.status.busy":"2022-09-04T17:19:25.871359Z","iopub.status.idle":"2022-09-04T17:19:25.885482Z","shell.execute_reply":"2022-09-04T17:19:25.884322Z","shell.execute_reply.started":"2022-09-04T17:19:25.871636Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BloomConfig {\n","  \"_name_or_path\": \"bigscience/bloom-560m\",\n","  \"apply_residual_connection_post_layernorm\": false,\n","  \"architectures\": [\n","    \"BloomModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_softmax_in_fp32\": true,\n","  \"bias_dropout_fusion\": true,\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"masked_softmax_fusion\": true,\n","  \"model_type\": \"bloom\",\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 24,\n","  \"offset_alibi\": 100,\n","  \"pad_token_id\": 3,\n","  \"pretraining_tp\": 1,\n","  \"seq_length\": 2048,\n","  \"skip_bias_add\": true,\n","  \"skip_bias_add_qkv\": false,\n","  \"slow_but_exact\": false,\n","  \"transformers_version\": \"4.21.2\",\n","  \"unk_token_id\": 0,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250880\n","}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model.config"]},{"cell_type":"markdown","metadata":{},"source":["**Predict Token Classification:**\n","\n","Since Bloom has not been fintuned for Token classification yet, the prediction is poor as expected."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["text = \"\"\"\n","Für Richard Phillips Feynman war es immer wichtig, die unanschaulichen \n","Gesetzmäßigkeiten der Quantenphysik Laien und Studenten nahezubringen und verständlich zu machen.\n","\"\"\""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0']\n"]}],"source":["inputs = tokenizer(\n","    text, add_special_tokens=False, return_tensors=\"pt\"\n",")\n","\n","with torch.no_grad():\n","    logits = model(**inputs).logits\n","\n","predicted_token_class_ids = logits.argmax(-1)\n","\n","# Note that tokens are classified rather then input words which means that\n","# there might be more predicted token classes than words.\n","# Multiple token classes might account for the same word\n","predicted_tokens_classes = [model.config.id2label[t.item()] for t in predicted_token_class_ids[0]]\n","print(predicted_tokens_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"72a3b8d639f2747ab586194b4ca9ce337f16fb375d739e56b4629a0a8f86dcaa"}}},"nbformat":4,"nbformat_minor":4}
